#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø·Ø±ÙŠÙ‚Ø© CSV Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª .bok
"""

import pandas as pd
import os
import sys
import csv
from pathlib import Path

class CSVBokExtractor:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV Ù…ÙØµØ¯Ø±Ø© Ù…Ù† Access"""
    
    def __init__(self):
        self.csv_folder = r"d:\test3\data\csv_exports"
        Path(self.csv_folder).mkdir(parents=True, exist_ok=True)
    
    def guide_manual_export(self, bok_file):
        """Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØµØ¯ÙŠØ± Ø§Ù„ÙŠØ¯ÙˆÙŠ"""
        print("ğŸ“‹ Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØµØ¯ÙŠØ± Ø§Ù„ÙŠØ¯ÙˆÙŠ Ù…Ù† Access:")
        print("=" * 50)
        print("1. Ø§ÙØªØ­ Ù…Ù„Ù .bok ÙÙŠ Microsoft Access")
        print("2. Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ External Data > Export > Text File")
        print("3. ØµØ¯Ù‘Ø± Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ©:")
        print("   - Main Ø£Ùˆ TBMain (Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø§Øª)")
        print("   - TBTitles Ø£Ùˆ Index (ÙÙ‡Ø±Ø³ Ø§Ù„ÙƒØªØ§Ø¨)")
        print("   - Books Ø£Ùˆ BookInfo (Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙƒØªØ§Ø¨)")
        print("4. Ø§Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ù…Ø¬Ù„Ø¯:", self.csv_folder)
        print("5. Ø´ØºÙ‘Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ù…Ø±Ø© Ø£Ø®Ø±Ù‰")
        print("=" * 50)
    
    def process_csv_files(self, book_name):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª CSV"""
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª CSV
            csv_files = list(Path(self.csv_folder).glob("*.csv"))
            
            if not csv_files:
                print("âŒ Ù„Ù… ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª CSV")
                self.guide_manual_export(None)
                return None
            
            print(f"ğŸ“ ÙˆÙØ¬Ø¯ {len(csv_files)} Ù…Ù„Ù CSV:")
            for csv_file in csv_files:
                print(f"  - {csv_file.name}")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª
            content_file = self.find_content_file(csv_files)
            index_file = self.find_index_file(csv_files)
            
            if not content_file:
                print("âŒ Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰")
                return None
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            content_data = self.read_content_csv(content_file)
            index_data = self.read_index_csv(index_file) if index_file else []
            
            return {
                'content_data': content_data,
                'index_data': index_data,
                'book_info': {'title': book_name}
            }
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© CSV: {str(e)}")
            return None
    
    def find_content_file(self, csv_files):
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        content_keywords = ['main', 'tbmain', 'content', 'pages', 'nass']
        
        for csv_file in csv_files:
            name_lower = csv_file.name.lower()
            if any(keyword in name_lower for keyword in content_keywords):
                print(f"âœ… Ù…Ù„Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {csv_file.name}")
                return csv_file
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ØŒ Ù†Ø£Ø®Ø° Ø£ÙƒØ¨Ø± Ù…Ù„Ù
        largest_file = max(csv_files, key=lambda f: f.stat().st_size)
        print(f"ğŸ” Ø£Ø®Ø° Ø£ÙƒØ¨Ø± Ù…Ù„Ù ÙƒÙ…Ø­ØªÙˆÙ‰: {largest_file.name}")
        return largest_file
    
    def find_index_file(self, csv_files):
        """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„Ù Ø§Ù„ÙÙ‡Ø±Ø³"""
        index_keywords = ['titles', 'tbtitles', 'index', 'fihris', 'chapters']
        
        for csv_file in csv_files:
            name_lower = csv_file.name.lower()
            if any(keyword in name_lower for keyword in index_keywords):
                print(f"âœ… Ù…Ù„Ù Ø§Ù„ÙÙ‡Ø±Ø³: {csv_file.name}")
                return csv_file
        
        print("âš ï¸ Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„Ù‰ Ù…Ù„Ù ÙÙ‡Ø±Ø³")
        return None
    
    def read_content_csv(self, csv_file):
        """Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ù…Ø­ØªÙˆÙ‰ CSV"""
        try:
            # Ø¬Ø±Ø¨ encodings Ù…Ø®ØªÙ„ÙØ©
            encodings = ['utf-8', 'cp1256', 'windows-1256', 'latin1']
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(csv_file, encoding=encoding)
                    print(f"âœ… Ù‚ÙØ±Ø¦ Ø¨Ù€ {encoding}: {len(df)} Ø³Ø¬Ù„")
                    break
                except UnicodeDecodeError:
                    continue
            else:
                print("âŒ ÙØ´Ù„ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ±Ù…ÙŠØ²Ø§Øª")
                return []
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨
            content_data = []
            
            for _, row in df.iterrows():
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                page_num = self.extract_page_number(row)
                content = self.extract_content(row)
                part = self.extract_part(row)
                
                if content:  # ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø­ØªÙˆÙ‰
                    content_data.append({
                        'page': page_num,
                        'id': page_num,
                        'nass': content,
                        'part': part
                    })
            
            print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(content_data)} ØµÙØ­Ø© Ù…Ø­ØªÙˆÙ‰")
            return content_data
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {str(e)}")
            return []
    
    def read_index_csv(self, csv_file):
        """Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù ÙÙ‡Ø±Ø³ CSV"""
        try:
            encodings = ['utf-8', 'cp1256', 'windows-1256', 'latin1']
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(csv_file, encoding=encoding)
                    print(f"âœ… Ù‚ÙØ±Ø¦ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¨Ù€ {encoding}: {len(df)} Ø³Ø¬Ù„")
                    break
                except UnicodeDecodeError:
                    continue
            else:
                return []
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨
            index_data = []
            
            for _, row in df.iterrows():
                page_num = self.extract_page_number(row)
                title = self.extract_title(row)
                level = self.extract_level(row)
                
                if title:  # ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ù†ÙˆØ§Ù†
                    index_data.append({
                        'id': page_num,
                        'tit': title,
                        'lvl': level or 1
                    })
            
            print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(index_data)} Ø¹Ù†ØµØ± ÙÙ‡Ø±Ø³")
            return index_data
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„ÙÙ‡Ø±Ø³: {str(e)}")
            return []
    
    def extract_page_number(self, row):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø©"""
        page_columns = ['page', 'pagenum', 'id', 'Ø±Ù‚Ù…_Ø§Ù„ØµÙØ­Ø©', 'Ø±Ù‚Ù…']
        
        for col in page_columns:
            if col in row and pd.notna(row[col]):
                try:
                    return int(row[col])
                except:
                    pass
        
        # Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙÙ‡Ø±Ø³ ÙƒØ±Ù‚Ù… ØµÙØ­Ø©
        return row.name + 1
    
    def extract_content(self, row):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        content_columns = ['nass', 'content', 'text', 'Ù…Ø­ØªÙˆÙ‰', 'Ù†Øµ']
        
        for col in content_columns:
            if col in row and pd.notna(row[col]):
                return str(row[col]).strip()
        
        # Ø£Ø®Ø° Ø£Ø·ÙˆÙ„ Ù†Øµ ÙÙŠ Ø§Ù„Ø³Ø·Ø±
        text_values = [str(val) for val in row.values if pd.notna(val) and len(str(val)) > 10]
        return max(text_values, key=len) if text_values else ""
    
    def extract_part(self, row):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ø¬Ø²Ø¡"""
        part_columns = ['part', 'Ø¬Ø²Ø¡', 'volume']
        
        for col in part_columns:
            if col in row and pd.notna(row[col]):
                try:
                    return int(row[col])
                except:
                    pass
        
        return None
    
    def extract_title(self, row):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†"""
        title_columns = ['title', 'tit', 'Ø¹Ù†ÙˆØ§Ù†', 'Ø§Ø³Ù…']
        
        for col in title_columns:
            if col in row and pd.notna(row[col]):
                return str(row[col]).strip()
        
        # Ø£Ø®Ø° Ø£ÙˆÙ„ Ù†Øµ ØºÙŠØ± Ø±Ù‚Ù…ÙŠ
        for val in row.values:
            if pd.notna(val) and not str(val).isdigit() and len(str(val)) > 2:
                return str(val).strip()
        
        return ""
    
    def extract_level(self, row):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†"""
        level_columns = ['level', 'lvl', 'Ù…Ø³ØªÙˆÙ‰']
        
        for col in level_columns:
            if col in row and pd.notna(row[col]):
                try:
                    return int(row[col])
                except:
                    pass
        
        return 1

def main():
    """Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª CSV")
    print("=" * 50)
    
    extractor = CSVBokExtractor()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª CSV
    csv_files = list(Path(extractor.csv_folder).glob("*.csv"))
    
    if not csv_files:
        print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª CSV")
        extractor.guide_manual_export(None)
        return
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
    book_name = "ÙƒØªØ§Ø¨ ØªØ¬Ø±ÙŠØ¨ÙŠ"
    result = extractor.process_csv_files(book_name)
    
    if result:
        print("\nâœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"ğŸ“„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {len(result['content_data'])} ØµÙØ­Ø©")
        print(f"ğŸ“š Ø§Ù„ÙÙ‡Ø±Ø³: {len(result['index_data'])} Ø¹Ù†ØµØ±")
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø©
        if result['content_data']:
            sample = result['content_data'][0]
            print(f"ğŸ“‹ Ø¹ÙŠÙ†Ø© Ù…Ø­ØªÙˆÙ‰: ØµÙØ­Ø© {sample.get('page', 'ØŸ')} - {sample.get('nass', '')[:50]}...")
    else:
        print("âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

if __name__ == "__main__":
    main()
    input("\nØ§Ø¶ØºØ· Enter Ù„Ù„Ø®Ø±ÙˆØ¬...")
